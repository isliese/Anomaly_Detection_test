import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timezone
import warnings
warnings.filterwarnings('ignore')

class CryptoAnomalyDetector:
    def __init__(self, data, coin_name):
        self.data = data.copy()
        self.coin_name = coin_name
        self.prepare_data()
        
    def prepare_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§"""
        # timestampë¥¼ datetimeìœ¼ë¡œ ë³€í™˜ (UTC ê¸°ì¤€)
        self.data['datetime'] = pd.to_datetime(self.data['timestamp'], unit='ms', utc=True)
        
        # ê¸°ë³¸ ê°€ê²© ë³€ë™ë¥  ê³„ì‚°
        self.data['price_change'] = self.data['close'].pct_change()
        self.data['price_change_abs'] = abs(self.data['price_change'])
        
        # ê°€ê²© ë³€ë™ì„± (high-low spread)
        self.data['hl_spread'] = (self.data['high'] - self.data['low']) / self.data['close']
        
        # ê±°ë˜ëŸ‰ ë³€í™”ìœ¨
        self.data['volume_change'] = self.data['volume'].pct_change()
        self.data['volume_change_abs'] = abs(self.data['volume_change'])
        
        # ê°€ê²©-ê±°ë˜ëŸ‰ ê³± (ê±°ë˜ëŒ€ê¸ˆ)
        self.data['turnover'] = self.data['close'] * self.data['volume']
        self.data['turnover_change'] = self.data['turnover'].pct_change()
        
        # ë¡¤ë§ í†µê³„ëŸ‰ ê³„ì‚° (5ë¶„, 15ë¶„, 30ë¶„ ìœˆë„ìš°)
        for window in [5, 15, 30]:
            self.data[f'price_volatility_{window}m'] = self.data['price_change'].rolling(window).std()
            self.data[f'volume_ma_{window}m'] = self.data['volume'].rolling(window).mean()
            self.data[f'volume_std_{window}m'] = self.data['volume'].rolling(window).std()
            
        # NaN ê°’ ì œê±°
        self.data = self.data.dropna().reset_index(drop=True)
    
    def method1_statistical_outliers(self, columns=['price_change_abs', 'volume_change_abs'], 
                                   threshold_method='iqr', z_threshold=3, iqr_multiplier=1.5):
        """ë°©ë²• 1: í†µê³„ì  ì´ìƒì¹˜ íƒì§€ (Z-score, IQR)"""
        print("=" * 60)
        print(f"ë°©ë²• 1: í†µê³„ì  ì´ìƒì¹˜ íƒì§€ - {self.coin_name}")
        print("=" * 60)
        
        results = {}
        total_outliers = 0
        
        for col in columns:
            if col not in self.data.columns:
                continue
                
            if threshold_method == 'zscore':
                # Z-score ë°©ë²•
                z_scores = np.abs((self.data[col] - self.data[col].mean()) / self.data[col].std())
                outliers = z_scores > z_threshold
                threshold_value = z_threshold
                method_name = f"Z-score (ì„ê³„ê°’: {z_threshold})"
                
            elif threshold_method == 'iqr':
                # IQR ë°©ë²•
                Q1 = self.data[col].quantile(0.25)
                Q3 = self.data[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - iqr_multiplier * IQR
                upper_bound = Q3 + iqr_multiplier * IQR
                outliers = (self.data[col] < lower_bound) | (self.data[col] > upper_bound)
                threshold_value = iqr_multiplier
                method_name = f"IQR (ë°°ìˆ˜: {iqr_multiplier})"
            
            outlier_count = outliers.sum()
            outlier_percentage = (outlier_count / len(self.data)) * 100
            total_outliers += outlier_count
            
            results[col] = {
                'method': method_name,
                'outliers': outliers,
                'count': outlier_count,
                'percentage': outlier_percentage,
                'outlier_indices': self.data[outliers].index.tolist()
            }
            
            print(f"\nğŸ“Š {col} ë¶„ì„ ê²°ê³¼ ({method_name}):")
            print(f"   - ì´ìƒì¹˜ ê°œìˆ˜: {outlier_count}ê°œ ({outlier_percentage:.2f}%)")
            print(f"   - í‰ê· : {self.data[col].mean():.6f}")
            print(f"   - í‘œì¤€í¸ì°¨: {self.data[col].std():.6f}")
            
            if outlier_count > 0:
                outlier_data = self.data[outliers]
                print(f"   - ì´ìƒì¹˜ ìµœëŒ€ê°’: {self.data[col][outliers].max():.6f}")
                print(f"   - ì´ìƒì¹˜ ë°œìƒ ì‹œê°„ (ìµœê·¼ 5ê°œ):")
                for idx in outlier_data.index[-5:]:
                    print(f"     {self.data.loc[idx, 'datetime'].strftime('%Y-%m-%d %H:%M:%S')} - ê°’: {self.data.loc[idx, col]:.6f}")
        
        results['total_outliers'] = total_outliers
        return results
    
    def method2_rolling_deviation(self, windows=[5, 15, 30], threshold_multiplier=2.5):
        """ë°©ë²• 2: ë¡¤ë§ ìœˆë„ìš° ê¸°ë°˜ í¸ì°¨ ë¶„ì„"""
        print("\n" + "=" * 60)
        print(f"ë°©ë²• 2: ë¡¤ë§ ìœˆë„ìš° ê¸°ë°˜ í¸ì°¨ ë¶„ì„ - {self.coin_name}")
        print("=" * 60)
        
        results = {}
        total_combined_anomalies = 0
        
        for window in windows:
            print(f"\nğŸ“ˆ {window}ë¶„ ìœˆë„ìš° ë¶„ì„:")
            
            # ê°€ê²© ë³€ë™ì„± ì´ìƒì¹˜
            price_volatility_col = f'price_volatility_{window}m'
            if price_volatility_col in self.data.columns:
                vol_mean = self.data[price_volatility_col].mean()
                vol_std = self.data[price_volatility_col].std()
                vol_threshold = vol_mean + threshold_multiplier * vol_std
                
                price_anomalies = self.data[price_volatility_col] > vol_threshold
                price_anomaly_count = price_anomalies.sum()
                
                print(f"   ê°€ê²© ë³€ë™ì„± ì´ìƒì¹˜: {price_anomaly_count}ê°œ ({(price_anomaly_count/len(self.data)*100):.2f}%)")
                print(f"   ì„ê³„ê°’: {vol_threshold:.6f} (í‰ê·  + {threshold_multiplier}Ïƒ)")
            
            # ê±°ë˜ëŸ‰ ì´ìƒì¹˜
            volume_std_col = f'volume_std_{window}m'
            if volume_std_col in self.data.columns:
                vol_std_mean = self.data[volume_std_col].mean()
                vol_std_std = self.data[volume_std_col].std()
                vol_std_threshold = vol_std_mean + threshold_multiplier * vol_std_std
                
                volume_anomalies = self.data[volume_std_col] > vol_std_threshold
                volume_anomaly_count = volume_anomalies.sum()
                
                print(f"   ê±°ë˜ëŸ‰ ë³€ë™ì„± ì´ìƒì¹˜: {volume_anomaly_count}ê°œ ({(volume_anomaly_count/len(self.data)*100):.2f}%)")
                print(f"   ì„ê³„ê°’: {vol_std_threshold:.2f}")
            
            # ë³µí•© ì´ìƒì¹˜ (ê°€ê²© + ê±°ë˜ëŸ‰ ë™ì‹œ ë°œìƒ)
            if price_volatility_col in self.data.columns and volume_std_col in self.data.columns:
                combined_anomalies = price_anomalies & volume_anomalies
                combined_count = combined_anomalies.sum()
                total_combined_anomalies += combined_count
                print(f"   ë³µí•© ì´ìƒì¹˜ (ê°€ê²©+ê±°ë˜ëŸ‰): {combined_count}ê°œ ({(combined_count/len(self.data)*100):.2f}%)")
                
                results[f'{window}m'] = {
                    'price_anomalies': price_anomalies,
                    'volume_anomalies': volume_anomalies,
                    'combined_anomalies': combined_anomalies,
                    'combined_count': combined_count
                }
        
        results['total_combined_anomalies'] = total_combined_anomalies
        return results
    
    def method3_percentile_based(self, percentile_threshold=95):
        """ë°©ë²• 3: ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€"""
        print("\n" + "=" * 60)
        print(f"ë°©ë²• 3: ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€ ({percentile_threshold}th percentile) - {self.coin_name}")
        print("=" * 60)
        
        features = ['price_change_abs', 'volume_change_abs', 'hl_spread', 'turnover_change']
        results = {}
        total_anomalies = 0
        
        for feature in features:
            if feature not in self.data.columns:
                continue
                
            threshold = self.data[feature].quantile(percentile_threshold / 100)
            anomalies = self.data[feature] > threshold
            anomaly_count = anomalies.sum()
            total_anomalies += anomaly_count
            
            results[feature] = {
                'threshold': threshold,
                'anomalies': anomalies,
                'count': anomaly_count,
                'percentage': (anomaly_count / len(self.data)) * 100
            }
            
            print(f"\nğŸ“Š {feature}:")
            print(f"   - {percentile_threshold}th percentile ì„ê³„ê°’: {threshold:.6f}")
            print(f"   - ì´ìƒì¹˜ ê°œìˆ˜: {anomaly_count}ê°œ ({(anomaly_count/len(self.data)*100):.2f}%)")
            
            if anomaly_count > 0:
                anomaly_times = self.data[anomalies]['datetime'].tail(3)
                print(f"   - ìµœê·¼ ì´ìƒì¹˜ ë°œìƒ ì‹œê°„:")
                for dt in anomaly_times:
                    print(f"     {dt.strftime('%Y-%m-%d %H:%M:%S')}")
        
        results['total_anomalies'] = total_anomalies
        return results
    
    def method4_composite_anomaly_score(self):
        """ë°©ë²• 4: ë³µí•© ì´ìƒì¹˜ ì ìˆ˜ ê³„ì‚°"""
        print("\n" + "=" * 60)
        print(f"ë°©ë²• 4: ë³µí•© ì´ìƒì¹˜ ì ìˆ˜ (ì‹¤ì‹œê°„ ëª¨ë¸ìš©) - {self.coin_name}")
        print("=" * 60)
        
        # ì •ê·œí™”ëœ ì ìˆ˜ ê³„ì‚°
        features = ['price_change_abs', 'volume_change_abs', 'hl_spread']
        scores = pd.DataFrame()
        
        for feature in features:
            if feature in self.data.columns:
                # 0-1 ìŠ¤ì¼€ì¼ë§ (ìµœê·¼ 30ë¶„ ê¸°ì¤€)
                rolling_min = self.data[feature].rolling(window=30, min_periods=1).min()
                rolling_max = self.data[feature].rolling(window=30, min_periods=1).max()
                
                normalized = (self.data[feature] - rolling_min) / (rolling_max - rolling_min + 1e-8)
                scores[feature] = normalized.fillna(0)
        
        # ê°€ì¤‘ ë³µí•© ì ìˆ˜ (ê°€ê²© ë³€ë™: 40%, ê±°ë˜ëŸ‰ ë³€ë™: 40%, ìŠ¤í”„ë ˆë“œ: 20%)
        weights = {'price_change_abs': 0.4, 'volume_change_abs': 0.4, 'hl_spread': 0.2}
        
        composite_score = pd.Series(0, index=self.data.index)
        for feature, weight in weights.items():
            if feature in scores.columns:
                composite_score += scores[feature] * weight
        
        self.data['anomaly_score'] = composite_score
        
        # ì´ìƒì¹˜ ì„ê³„ê°’ ì„¤ì • (ìƒìœ„ 5%)
        anomaly_threshold = composite_score.quantile(0.95)
        high_anomalies = composite_score > anomaly_threshold
        
        print(f"ğŸ“Š ë³µí•© ì´ìƒì¹˜ ì ìˆ˜ ë¶„ì„:")
        print(f"   - í‰ê·  ì ìˆ˜: {composite_score.mean():.4f}")
        print(f"   - ìµœëŒ€ ì ìˆ˜: {composite_score.max():.4f}")
        print(f"   - ì´ìƒì¹˜ ì„ê³„ê°’ (95th percentile): {anomaly_threshold:.4f}")
        print(f"   - ê³ ìœ„í—˜ ì´ìƒì¹˜: {high_anomalies.sum()}ê°œ ({(high_anomalies.sum()/len(self.data)*100):.2f}%)")
        
        # ìµœê³  ì ìˆ˜ ìƒìœ„ 5ê°œ ì‹œì 
        top_anomalies = self.data.nlargest(5, 'anomaly_score')
        print(f"\nğŸš¨ ìµœê³  ì´ìƒì¹˜ ì ìˆ˜ TOP 5:")
        for idx, row in top_anomalies.iterrows():
            print(f"   {row['datetime'].strftime('%Y-%m-%d %H:%M:%S')} - ì ìˆ˜: {row['anomaly_score']:.4f}")
            print(f"      ê°€ê²©ë³€ë™: {row['price_change_abs']:.4f}, ê±°ë˜ëŸ‰ë³€ë™: {row['volume_change_abs']:.4f}")
        
        return composite_score, anomaly_threshold, high_anomalies.sum()
    
    def analyze_trading_patterns(self):
        """ê±°ë˜ íŒ¨í„´ ë¶„ì„"""
        print("\n" + "=" * 60)
        print(f"ê±°ë˜ íŒ¨í„´ ë° ì¸ì‚¬ì´íŠ¸ ë¶„ì„ - {self.coin_name}")
        print("=" * 60)
        
        # ì‹œê°„ëŒ€ë³„ ë¶„ì„
        self.data['hour'] = self.data['datetime'].dt.hour
        hourly_stats = self.data.groupby('hour').agg({
            'volume': ['mean', 'std'],
            'price_change_abs': ['mean', 'std'],
            'hl_spread': 'mean'
        }).round(4)
        
        print("\nâ° ì‹œê°„ëŒ€ë³„ ê±°ë˜ í™œë™:")
        print("ì‹œê°„\tê±°ë˜ëŸ‰(í‰ê· )\tê°€ê²©ë³€ë™(í‰ê· )\tìŠ¤í”„ë ˆë“œ(í‰ê· )")
        for hour in range(24):
            if hour in hourly_stats.index:
                vol_mean = hourly_stats.loc[hour, ('volume', 'mean')]
                price_mean = hourly_stats.loc[hour, ('price_change_abs', 'mean')]
                spread_mean = hourly_stats.loc[hour, ('hl_spread', 'mean')]
                print(f"{hour:02d}ì‹œ\t{vol_mean:,.0f}\t\t{price_mean:.4f}\t\t{spread_mean:.4f}")
        
        # ê°€ê²©-ê±°ë˜ëŸ‰ ìƒê´€ê´€ê³„
        price_volume_corr = self.data['price_change_abs'].corr(self.data['volume_change_abs'])
        print(f"\nğŸ“ˆ ê°€ê²©ë³€ë™-ê±°ë˜ëŸ‰ë³€ë™ ìƒê´€ê³„ìˆ˜: {price_volume_corr:.4f}")
        
        # ë³€ë™ì„± í´ëŸ¬ìŠ¤í„°ë§ (ì—°ì†ëœ ê³ ë³€ë™ì„± êµ¬ê°„)
        high_volatility = self.data['price_change_abs'] > self.data['price_change_abs'].quantile(0.9)
        volatility_clusters = []
        cluster_start = None
        
        for i, is_high_vol in enumerate(high_volatility):
            if is_high_vol and cluster_start is None:
                cluster_start = i
            elif not is_high_vol and cluster_start is not None:
                if i - cluster_start >= 3:  # 3ë¶„ ì´ìƒ ì—°ì† ê³ ë³€ë™ì„±
                    volatility_clusters.append((cluster_start, i-1))
                cluster_start = None
        
        print(f"\nğŸ”¥ ë³€ë™ì„± í´ëŸ¬ìŠ¤í„° (3ë¶„ ì´ìƒ ì—°ì† ê³ ë³€ë™ì„±): {len(volatility_clusters)}ê°œ")
        for start, end in volatility_clusters[-3:]:  # ìµœê·¼ 3ê°œë§Œ ì¶œë ¥
            start_time = self.data.loc[start, 'datetime'].strftime('%H:%M:%S')
            end_time = self.data.loc[end, 'datetime'].strftime('%H:%M:%S')
            duration = end - start + 1
            print(f"   {start_time} ~ {end_time} ({duration}ë¶„ ì§€ì†)")
    
    def real_time_anomaly_model(self, lookback_window=30):
        """ì‹¤ì‹œê°„ ì´ìƒ íƒì§€ ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜"""
        print("\n" + "=" * 60)
        print(f"ì‹¤ì‹œê°„ ì´ìƒ íƒì§€ ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜ - {self.coin_name}")
        print("=" * 60)
        
        anomaly_scores = []
        anomaly_flags = []
        
        for i in range(lookback_window, len(self.data)):
            # í˜„ì¬ ì‹œì 
            current = self.data.iloc[i]
            
            # ê³¼ê±° lookback_window ê¸°ê°„ì˜ ê¸°ì¤€ê°’ ê³„ì‚°
            historical_data = self.data.iloc[i-lookback_window:i]
            
            # ê¸°ì¤€ í†µê³„ëŸ‰
            price_vol_mean = historical_data['price_change_abs'].mean()
            price_vol_std = historical_data['price_change_abs'].std()
            volume_mean = historical_data['volume'].mean()
            volume_std = historical_data['volume'].std()
            
            # í˜„ì¬ ê°’ì˜ ì´ìƒ ì •ë„ ê³„ì‚°
            price_anomaly_score = abs(current['price_change_abs'] - price_vol_mean) / (price_vol_std + 1e-8)
            volume_anomaly_score = abs(current['volume'] - volume_mean) / (volume_std + 1e-8)
            
            # ë³µí•© ì ìˆ˜ (0-1 ìŠ¤ì¼€ì¼)
            composite_score = min(1.0, (price_anomaly_score * 0.6 + volume_anomaly_score * 0.4) / 5)
            
            # ì´ìƒì¹˜ í”Œë˜ê·¸ (ì ìˆ˜ > 0.7)
            is_anomaly = composite_score > 0.7
            
            anomaly_scores.append(composite_score)
            anomaly_flags.append(is_anomaly)
        
        # ê²°ê³¼ ì €ì¥
        start_idx = lookback_window
        self.data.loc[start_idx:, 'realtime_anomaly_score'] = anomaly_scores
        self.data.loc[start_idx:, 'realtime_anomaly_flag'] = anomaly_flags
        
        # í†µê³„
        total_anomalies = sum(anomaly_flags)
        print(f"ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë¸ ì„±ëŠ¥:")
        print(f"   - ë¶„ì„ ëŒ€ìƒ ê¸°ê°„: {len(anomaly_scores)}ë¶„")
        print(f"   - íƒì§€ëœ ì´ìƒì¹˜: {total_anomalies}ê°œ ({(total_anomalies/len(anomaly_scores)*100):.2f}%)")
        print(f"   - í‰ê·  ì´ìƒì¹˜ ì ìˆ˜: {np.mean(anomaly_scores):.4f}")
        print(f"   - ìµœëŒ€ ì´ìƒì¹˜ ì ìˆ˜: {max(anomaly_scores):.4f}")
        
        # ìµœê·¼ ì´ìƒì¹˜ 5ê°œ
        recent_anomalies = self.data[self.data['realtime_anomaly_flag'] == True].tail(5)
        if len(recent_anomalies) > 0:
            print(f"\nğŸš¨ ìµœê·¼ íƒì§€ëœ ì´ìƒì¹˜:")
            for idx, row in recent_anomalies.iterrows():
                print(f"   {row['datetime'].strftime('%H:%M:%S')} - ì ìˆ˜: {row['realtime_anomaly_score']:.4f}")
        
        return anomaly_scores, anomaly_flags, total_anomalies
    
    def visualize_results(self):
        """ê²°ê³¼ ì‹œê°í™”"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'{self.coin_name} ì´ìƒ ìƒí™© íƒì§€ ë¶„ì„ ê²°ê³¼', fontsize=16, fontweight='bold')
        
        # 1. ê°€ê²© ë³€ë™ë¥  ì‹œê³„ì—´
        axes[0,0].plot(self.data['datetime'], self.data['price_change_abs'], alpha=0.7, linewidth=0.8)
        axes[0,0].axhline(y=self.data['price_change_abs'].quantile(0.95), color='red', 
                        linestyle='--', label='95th percentile')
        axes[0,0].set_title('ê°€ê²© ë³€ë™ë¥  (ì ˆëŒ“ê°’)')
        axes[0,0].set_ylabel('ë³€ë™ë¥ ')
        axes[0,0].legend()
        axes[0,0].tick_params(axis='x', rotation=45)
        
        # 2. ê±°ë˜ëŸ‰ ì‹œê³„ì—´
        axes[0,1].plot(self.data['datetime'], self.data['volume'], alpha=0.7, linewidth=0.8, color='green')
        axes[0,1].axhline(y=self.data['volume'].quantile(0.95), color='red', 
                        linestyle='--', label='95th percentile')
        axes[0,1].set_title('ê±°ë˜ëŸ‰')
        axes[0,1].set_ylabel('ê±°ë˜ëŸ‰')
        axes[0,1].legend()
        axes[0,1].tick_params(axis='x', rotation=45)
        
        # 3. ë³µí•© ì´ìƒì¹˜ ì ìˆ˜
        if 'anomaly_score' in self.data.columns:
            axes[1,0].plot(self.data['datetime'], self.data['anomaly_score'], 
                        alpha=0.8, linewidth=1, color='purple')
            axes[1,0].axhline(y=0.7, color='red', linestyle='--', label='ì´ìƒì¹˜ ì„ê³„ê°’ (0.7)')
            axes[1,0].set_title('ë³µí•© ì´ìƒì¹˜ ì ìˆ˜')
            axes[1,0].set_ylabel('ì ìˆ˜')
            axes[1,0].legend()
            axes[1,0].tick_params(axis='x', rotation=45)
        
        # 4. ê°€ê²©-ê±°ë˜ëŸ‰ ì‚°ì ë„
        scatter_sample = self.data.sample(min(500, len(self.data)))  # ìƒ˜í”Œë§ìœ¼ë¡œ ì‹œê°í™” ê°œì„ 
        scatter = axes[1,1].scatter(scatter_sample['price_change_abs'], 
                                scatter_sample['volume_change_abs'],
                                alpha=0.6, s=20)
        axes[1,1].set_xlabel('ê°€ê²© ë³€ë™ë¥  (ì ˆëŒ“ê°’)')
        axes[1,1].set_ylabel('ê±°ë˜ëŸ‰ ë³€ë™ë¥  (ì ˆëŒ“ê°’)')
        axes[1,1].set_title('ê°€ê²© vs ê±°ë˜ëŸ‰ ë³€ë™ ê´€ê³„')
        
        plt.tight_layout()
        plt.show()
        
        # ì¶”ê°€ ë¶„ì„ ì°¨íŠ¸
        self.plot_anomaly_distribution()

    def plot_anomaly_distribution(self):
        """ì´ìƒì¹˜ ë¶„í¬ ë¶„ì„ ì°¨íŠ¸"""
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))
        
        # ì´ìƒì¹˜ ì ìˆ˜ ë¶„í¬
        if 'anomaly_score' in self.data.columns:
            axes[0].hist(self.data['anomaly_score'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
            axes[0].axvline(x=0.7, color='red', linestyle='--', label='ì„ê³„ê°’ (0.7)')
            axes[0].set_title('ì´ìƒì¹˜ ì ìˆ˜ ë¶„í¬')
            axes[0].set_xlabel('ì ìˆ˜')
            axes[0].set_ylabel('ë¹ˆë„')
            axes[0].legend()
        
        # ì‹œê°„ëŒ€ë³„ ì´ìƒì¹˜ ë°œìƒ ë¹ˆë„
        if 'realtime_anomaly_flag' in self.data.columns:
            hourly_anomalies = self.data.groupby('hour')['realtime_anomaly_flag'].sum()
            axes[1].bar(hourly_anomalies.index, hourly_anomalies.values, alpha=0.7, color='coral')
            axes[1].set_title('ì‹œê°„ëŒ€ë³„ ì´ìƒì¹˜ ë°œìƒ ë¹ˆë„')
            axes[1].set_xlabel('ì‹œê°„ (UTC)')
            axes[1].set_ylabel('ì´ìƒì¹˜ ë°œìƒ íšŸìˆ˜')
            axes[1].set_xticks(range(0, 24, 2))
        
        plt.tight_layout()
        plt.show()


def print_ranking_summary(method_results):
    """ê° ë°©ë²•ë³„ ì´ìƒì¹˜ íƒì§€ ìˆœìœ„ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print("ğŸ† ì´ìƒì¹˜ íƒì§€ ë°©ë²•ë³„ ì½”ì¸ ìˆœìœ„ (ì´ìƒì¹˜ ë§ì´ ë°œê²¬ëœ ìˆœ)")
    print("=" * 80)
    
    for method_name, results in method_results.items():
        print(f"\nğŸ“ˆ {method_name}")
        print("-" * 50)
        
        # ê²°ê³¼ë¥¼ ì´ìƒì¹˜ ê°œìˆ˜ë¡œ ì •ë ¬
        sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)
        
        for rank, (coin, count) in enumerate(sorted_results, 1):
            print(f"   {rank}ìœ„: {coin:8s} - {count:4d}ê°œ ì´ìƒì¹˜")


# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    # CSV íŒŒì¼ ê²½ë¡œ
    file_path_dic = {
        r"candle_data\candle_data\ADA.csv": "ADA", 
        r"candle_data\candle_data\BERA.csv": "BERA", 
        r"candle_data\candle_data\ETH.csv": "ETH", 
        r"candle_data\candle_data\PENGU.csv": "PENGU",
        r"candle_data\candle_data\SOON.csv": "SOON", 
        r"candle_data\candle_data\SUNDOG.csv": "SUNDOG", 
        r"candle_data\candle_data\XRP.csv": "XRP", 
        r"candle_data\candle_data\YFI.csv": "YFI"
    }

    # ê° ë°©ë²•ë³„ ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
    method1_results = {}  # í†µê³„ì  ì´ìƒì¹˜
    method2_results = {}  # ë¡¤ë§ ìœˆë„ìš°
    method3_results = {}  # ë°±ë¶„ìœ„ìˆ˜
    method4_results = {}  # ë³µí•© ì ìˆ˜
    realtime_results = {}  # ì‹¤ì‹œê°„ ëª¨ë¸

    # ê° íŒŒì¼ë³„ë¡œ ë¶„ì„ ì‹¤í–‰ 
    for file_path, coin_name in file_path_dic.items():
        print(f"\n{'='*80}")
        print(f"ğŸ” {coin_name} ë¶„ì„ ì‹œì‘")
        print(f"{'='*80}")
        
        try:
            # CSV íŒŒì¼ ì½ê¸°
            df = pd.read_csv(file_path)
            
            # í•„ìš”í•œ ì»¬ëŸ¼ ì„ íƒ ë° ì´ë¦„ ì •ë¦¬
            df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]
            
            # CryptoAnomalyDetector ì´ˆê¸°í™”
            detector = CryptoAnomalyDetector(df, coin_name)
            
            # ë°©ë²• 1: í†µê³„ì  ì´ìƒì¹˜ íƒì§€
            result1 = detector.method1_statistical_outliers()
            method1_results[coin_name] = result1.get('total_outliers', 0)
            
            # ë°©ë²• 2: ë¡¤ë§ ìœˆë„ìš° ê¸°ë°˜ í¸ì°¨ ë¶„ì„
            result2 = detector.method2_rolling_deviation()
            method2_results[coin_name] = result2.get('total_combined_anomalies', 0)
            
            # ë°©ë²• 3: ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€
            result3 = detector.method3_percentile_based()
            method3_results[coin_name] = result3.get('total_anomalies', 0)
            
            # ë°©ë²• 4: ë³µí•© ì´ìƒì¹˜ ì ìˆ˜ ê³„ì‚°
            composite_score, anomaly_threshold, high_anomaly_count = detector.method4_composite_anomaly_score()
            method4_results[coin_name] = high_anomaly_count
            
            # ê±°ë˜ íŒ¨í„´ ë¶„ì„
            detector.analyze_trading_patterns()
            
            # ì‹¤ì‹œê°„ ì´ìƒì¹˜ ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜
            anomaly_scores, anomaly_flags, realtime_anomaly_count = detector.real_time_anomaly_model()
            realtime_results[coin_name] = realtime_anomaly_count
            
            # ì‹œê°í™” (ì„ íƒì ìœ¼ë¡œ ì£¼ì„ í•´ì œ)
            # detector.visualize_results()
            
        except FileNotFoundError:
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            method1_results[coin_name] = 0
            method2_results[coin_name] = 0
            method3_results[coin_name] = 0
            method4_results[coin_name] = 0
            realtime_results[coin_name] = 0
            continue
        except Exception as e:
            print(f"âŒ {coin_name} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            method1_results[coin_name] = 0
            method2_results[coin_name] = 0
            method3_results[coin_name] = 0
            method4_results[coin_name] = 0
            realtime_results[coin_name] = 0
            continue

    # ì „ì²´ ê²°ê³¼ ìˆœìœ„ ì¶œë ¥
    all_method_results = {
        "ë°©ë²• 1: í†µê³„ì  ì´ìƒì¹˜ íƒì§€ (IQR)": method1_results,
        "ë°©ë²• 2: ë¡¤ë§ ìœˆë„ìš° ê¸°ë°˜ í¸ì°¨ ë¶„ì„": method2_results,
        "ë°©ë²• 3: ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€": method3_results,
        "ë°©ë²• 4: ë³µí•© ì´ìƒì¹˜ ì ìˆ˜": method4_results,
        "ì‹¤ì‹œê°„ ì´ìƒì¹˜ ëª¨ë¸": realtime_results
    }
    
    print_ranking_summary(all_method_results)
    
    # ì¢…í•© ìˆœìœ„ (ëª¨ë“  ë°©ë²•ì˜ í‰ê·  ìˆœìœ„)
    print("\n" + "=" * 80)
    print("ğŸ¯ ì¢…í•© ìˆœìœ„ (ëª¨ë“  ë°©ë²• í‰ê· )")
    print("=" * 80)
    
    coin_total_scores = {}
    for coin_name in file_path_dic.values():
        total_score = (
            method1_results.get(coin_name, 0) + 
            method2_results.get(coin_name, 0) + 
            method3_results.get(coin_name, 0) + 
            method4_results.get(coin_name, 0) + 
            realtime_results.get(coin_name, 0)
        )
        coin_total_scores[coin_name] = total_score
    
    sorted_total = sorted(coin_total_scores.items(), key=lambda x: x[1], reverse=True)
    
    print("\nğŸ“Š ì „ì²´ ì´ìƒì¹˜ ì¢…í•© ìˆœìœ„:")
    print("-" * 50)
    for rank, (coin, total_count) in enumerate(sorted_total, 1):
        print(f"   {rank}ìœ„: {coin:8s} - ì´ {total_count:4d}ê°œ ì´ìƒì¹˜")
        print(f"         (ë°©ë²•1: {method1_results.get(coin, 0):3d}, ë°©ë²•2: {method2_results.get(coin, 0):3d}, ë°©ë²•3: {method3_results.get(coin, 0):3d}, ë°©ë²•4: {method4_results.get(coin, 0):3d}, ì‹¤ì‹œê°„: {realtime_results.get(coin, 0):3d})")

    print("\n" + "=" * 80)
    print("âœ… ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("=" * 80)